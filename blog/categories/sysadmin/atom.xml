<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: sysadmin | CorgaLabs Blog]]></title>
  <link href="http://cmceniry.github.com/blog/categories/sysadmin/atom.xml" rel="self"/>
  <link href="http://cmceniry.github.com/"/>
  <updated>2014-07-13T00:35:29-07:00</updated>
  <id>http://cmceniry.github.com/</id>
  <author>
    <name><![CDATA[Chris McEniry]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What does The Cloud(tm) mean?]]></title>
    <link href="http://cmceniry.github.com/blog/2014/02/13/what-does-the-cloud-tm-mean/"/>
    <updated>2014-02-13T01:20:00-08:00</updated>
    <id>http://cmceniry.github.com/blog/2014/02/13/what-does-the-cloud-tm-mean</id>
    <content type="html"><![CDATA[<p>The Cloud (tm) - it’s a term that is far too encompassing of too many concepts.</p>

<p>At first, I thought the problem with describing it was that it was like the image of 10 blind people trying to say what an elephant was by each describing the one part they could feel. The more I think about it, that doesn’t even do it. The focus of that description is all about the "physical” description, but we’ve ascribed so much more into what we think of as The Cloud (tm). Not only do we talk about what it is, but also what it can do, and what it can allow others to do. It’d be the same as trying to describe how an elephant herd interacts, or how the use of domesticated elephants affected agriculture or helped win a war.</p>

<p>In short, it’s impact is just as and probably more important than just what it is. So, let’s look at both of those in turn.</p>

<p>Physically, the cloud is a combination of the multiple *aaSes that exist, but largely focused on Software, Infrastructure, and Platform. Disclosure: In my realm, I end up interacting with the latter two, so this is largely concerned with those. To be clear, I say Infrastructure-aaS and mean any product which provides an abstraction of compute, storage and networking, which allows a user to obtain resources in a low latency (ideally sub-minutes given with self-service and API interfaces) SLA. PaaS is similar to the above but focuses on the application container (e.g. servlet engine, dynamic web server backend, database) instead of infrastructure components. The Cloud (tm) can be public or private, it can be outsourced or internal, and it can even be service organizations in addition to true services.</p>

<p>We add confusion because all of these are “physical” descriptions, and so we tend to first compare on that level. Many look at The Cloud (tm) as a single solution (most of the time, it’s AWS, but it can also happen on the other side with internal solutions). But really, we want to agree on what aspects of those solutions are important and the trade off that those require.</p>

<p>So what are those aspects? What can The Cloud (tm) enable? Well, in not particular order, and definitely not complete:</p>

<ul>
<li><p>It can be a cash flow offset. It allows you to focus on leveled burn (operational expenses) rather than big bang spends with depreciation (capital expenditures). How much this matters depends how your corporate finances are structured.</p></li>
<li><p>It can provide dynamic resource commitments. You can purchase resources for short term usages. The dynamic capability leads to a need for rapidly providing and taking those away. How much this matters depends on your duty cycle, your bursts, and what margins are like with the provider.</p></li>
<li><p>It can provide rapid global ramp up of resources. From the last point, where you get those dynamic resources, you can choose where they go. How much this matters depends on your ability to configure those resources rapidly and the global properties of your application, as well as the provider capabilities (e.g. points of presence).</p></li>
<li><p>It can be automation point. Not talk about The Cloud (tm) can happen without some aspect of automation. Every cloud is built upon it. Every interaction asks the question “how can we automate it?”  How much this matters - well, it just matters. Your ability to execute on this drives how helpful it is.</p></li>
<li><p>It can change the semantics of application deployments. You move from talking about a build of an application or code package, and towards building (at least for now) machine images or container images (with application and dependent code inside). How much this matters depends on how you do your application configuration.</p></li>
<li><p>It can change the semantics of host and system management. You move from talking about individual hosts to talking about abstract roles or clusters. See <a href="http://blog.corgalabs.com/blog/2014/01/11/more-than-just-pets-and-cattle/">Pets and Cattle</a>.</p></li>
<li><p>It can provide you a way to level your production. If you’re not familiar with <a href="http://en.wikipedia.org/wiki/Production_leveling">Heijunka</a>, it’s a way to smooth out the flow of invetory through the delivery pipeline. Virtual environments enable you to provide the just the right resources just in time, by taking larger undifferentiated resources and honing them into what you need. Previously, you had to be very targeted and keep a lot of pre-differentiated products that can be used when need be. This leveling helps speed everything up without keeping around too much inventory. How much this matters depends on how many different resource types you really need, and how much overhead you’re willing to take.</p></li>
<li><p>It can let users take care of themselves. It can provide self-service in very structured ways. You can replace people and teams and service catalogs with APIs. Replace is probably the wrong word as someone or something needs to handle the underlying infrastructure of the service, and the service itself becomes a very codified service catalog. How much this matters depends on the level of responsibility being expected and accepted by the service users.</p></li>
<li><p>It can transfer work and risk to a third party. You can outsource what you deem to be noncritical and/or commoditized aspects of your business to others. The funny thing about risk is that it is rarely actually transferred. How much this matters depends on how tolerant of risk you are, how much you can negotiate, and how well you can handle this internally.</p></li>
</ul>


<p>Ultimately, it’s a matter of gaining some level of real or perceived efficiency. That efficiency can come in the form of economic (as in using for bursting, or cash flow changes), or in the form of faster changes, or in the form of shifting responsibilities, or probably others.</p>

<p>A lot of the above can be achieved without using The Cloud (tm), and many of the aspects run counter to each other (e.g. virtualization overhead versus flexibility). All in all that makes it impossible to say that The Cloud (tm) is goal. The goal is ultimately to make money, but the question is which aspect(s) of The Cloud (tm) do the best to get you that?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Firewall Rules from Models]]></title>
    <link href="http://cmceniry.github.com/blog/2013/03/19/firewall-rules-from-models/"/>
    <updated>2013-03-19T00:20:00-07:00</updated>
    <id>http://cmceniry.github.com/blog/2013/03/19/firewall-rules-from-models</id>
    <content type="html"><![CDATA[<p>I'm trying to put a little more meat to the bones of my <a href="http://blog.corgalabs.com/blog/2012/03/26/ancl-application-network-communication-language/">ANCL
discussion</a>. Unfortunately,
I can't say that I have a tool for it all, <em>yet</em>, but there's a bit
more of the theoretical basis for it. Some of the key requirements
forming around ANCL are:</p>

<ul>
<li><p>It abstracts the components involved - roles are used instead of
source IPs and destionation IPs.</p></li>
<li><p>It generalizes the communication patterns - models are built using
the roles; these models can be used in different locations by
identifying what composes the roles.</p></li>
<li><p>It can compose multiple models together - since the models are
composed of roles, using the same role in multiple models connects
them together (caveat in the second side note).</p></li>
</ul>


<p>I was reviewing some slidedecks and came across
<a href="https://github.com/bulletproofnetworks/ript">Ript</a> which has a <a href="https://speakerdeck.com/auxesis/ript-making-linux-firewall-change-management-resilient">good
presentation</a>. It
is a powerful abstraction over iptables. Bonus: It's abstraction can
even be carried to other stateful packet filters, software or
hardware.</p>

<p>Comparing it to ANCL, there's several key differences:</p>

<ul>
<li><p>A partition is not a connection of models, but a combination of
them. It's an administrative domain which lumps multiple unrelated
connections together. This is by far the biggest difference and is a
matter of the mental models.</p></li>
<li><p>The labels aren't the same as roles. They're good for identifying,
but they aren't then instantiated. There's a single mapping, when
multiple would be useful. This seems like an implementation detail
that could be easily addressed.</p></li>
<li><p>It's focus is on specific instantiations of the models. While the
rules would be portable to different devices, this limits its
ability to be ported to separate but similar situations. This seems
like it is a matter of changing conventions (e.g. the naming of the
labels), but might be more.</p></li>
</ul>


<p>The first item is what it really comes down to is that these are two
different mental and description models for the problem. Ript is a
firewall abstraction language, and not necessarily an application
communication description language. That being said, there are a great
many other pieces of Ript, not the least of it being something
concrete, that make it very useful and means I have some work here to
move ANCL to something that can compare.</p>

<hr />

<p>There's also two parts that Ript has also incorporated which I'll be
honest that I don't know how to incorporate into ANCL:</p>

<ul>
<li><p>NATs and SNATs and other translations. In many ways, these are not
critical to the application communication pattern, at least, not
critical at an abstract level. It's when it's applied in specific
contexts where translations come into play.</p></li>
<li><p>"Bad Guy" Rejects. Like transactions, these aren't critical to
application communication patterns - in fact, these are
anti-communication patterns. Necessary at times, but not something
that are accounted for when building the patterns.</p></li>
</ul>


<hr />

<p>The side note from above is that the roles aren't completely what are
connected to each other. Consider two models:</p>

<ol>
<li><p>A three tier application model which has a "webserver" role, an
"application" role, and a "DB" role.</p></li>
<li><p>A DB model which has an "application" role and a "DB" role.</p></li>
</ol>


<p>As the application owner of the first model, I would elaborate the
nodes in the "application" role. Most likely, the "DB" would be
specified by the DBA. Conversely, as the DB owner, I'd elaborate the
nodes in the "DB" role, and leave the "application" role to someone
else. In either case, half of the equation is left unfilled. There's
(at least) two ways to approach this:</p>

<ol>
<li><p>Since the key is to connect the two edges for the
"application"-"DB" together, the real role association happens
there. So, what language should be used to describe these "edge
roles"?</p></li>
<li><p>The ambiguity can be taken away if we insert "connection points" or
"service" points into each model. In this case, in the application
model, we replace the "DB" role with a "DB" connection point, and in
the DB model, we replace the "application" role with a "DB" connection
point. When joining these models together, we overlay the connection
points.</p></li>
</ol>


<p>Not sure which is the right way, so that'll probably comes down to
implementation.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitoring Discipline 1: Meter]]></title>
    <link href="http://cmceniry.github.com/blog/2012/10/02/monitoring-discipline-1-meter/"/>
    <updated>2012-10-02T23:52:00-07:00</updated>
    <id>http://cmceniry.github.com/blog/2012/10/02/monitoring-discipline-1-meter</id>
    <content type="html"><![CDATA[<p>In the last post, I talked about 4 different monitoring disciplines. In this, I'm talking about the first one: Meters; and try to distinguish some common Meter patterns.</p>

<p>I pick Meter for the first one for two reasons:</p>

<ul>
<li>It is the first one in the pipeline. It tends to be the closest to the feature being monitored.</li>
<li>It tends to be the mechanism that I (and I believe many others) think about first.</li>
</ul>


<p>The Meter is the basis of measurement. Whether it's counting the number of bytes going through a network interface, a recording of events generated from snmp traps, a log watcher, or a stream of metrics coming out of an application, the Meter is any item that can be measured or status checked and the path for sending the measurements to consumers who are interested in them. These are two fundamental and distinct sides. In earlier days, they were typically intermingled in one feature or tool, but now technologies allow for different distinctions between those.</p>

<p>There are two main categories of data types for the Meters: numeric, and event based. The primary difference for these is distinguishing between looking at a specific value (or an aggregate or nonvalue items), and looking at a specific event. Numeric values have a continuous meaning - the read at time t will have a different but just as significant meaning than the reading at time t+1. Events on the other hand are not discernable in time - if I receive an event at time t, I may not know the state of the system at t+1 (sometimes I can do another poll, sometimes I can't).</p>

<p>The Meter can use any number of mechanisms:</p>

<ul>
<li>SNMP Poll.</li>
<li>JMX Poll.</li>
<li>SNMP Trap.</li>
<li>Reviewing application logs and counting ERROR lines.</li>
<li>An application that exports mechanisms as a stream to some endpoint.</li>
<li>An application that sends events to a collector via syslog, a message queue or bus or chat protocol, an HTTP post to a web service, a generic mailbox mechanism.</li>
<li>An application that sends events via a message queue or bus to a collector.</li>
<li>A status/transactional check that grabs a web page and checks it for validity.</li>
</ul>


<p>We tend to want to turn Meters into a push versus pull argument, but it ends up being a false dicotomy. In many cases it depends on the perspective. An application which uses the <a href="https://github.com/codahale/metrics">metrics</a> will feel as it it's pushing those data points out, but the collection engine that uses it may pull those data points via JMX calls.</p>

<p>The key with Meter is identifying What you want to be watching. Everything else is plumbing (as if saying that makes it all easier).</p>

<p>Note: While it can't be discounted, the storage engine is not necessarily a part of the Meter. In many cases, the storage could also be used by the other disciplines. It's capabilities impact Meters, but it is a technology area more than an area of monitoring work.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Four Disciplines of Monitoring]]></title>
    <link href="http://cmceniry.github.com/blog/2012/08/15/four-disciplines-of-monitoring/"/>
    <updated>2012-08-15T10:39:00-07:00</updated>
    <id>http://cmceniry.github.com/blog/2012/08/15/four-disciplines-of-monitoring</id>
    <content type="html"><![CDATA[<p>(Release early, release often - a lot of the ideas here have some rough edges...)</p>

<p>There's been a lot of run around at work recently about how our monitoring system isn't sufficient. It's something that we all recognize and we want to put effort into fixing it, but I don't think we're all pulling the same direction.</p>

<p>Because we're not.</p>

<p>And to a degree that's ok. There's several different consumers of monitoring (or some variation on it), and each of us has different needs and wants out of it. That's all fine and good.</p>

<p>Where we're failing is trying to formulate our efforts together. Yeah, we can say we all have our own self-interests, or that we're a large company (which we're not really "large") and there's scale issues, or that we're all focused on tools and not as many on the real results (that's certainly true even though not everyone realizes it).</p>

<p>So, I'm trying to figure out the best way to address this. The key is to get us on the same page. Not that we have to have all of our concerns addressed, but more that we have them at least partially identified and shared with others. There's an added issue that we're all speaking different languages, or worse, the same language with many homophones. So, that brings me to this blog post.</p>

<p>There is a lot of confusion between Monitoring and Metrics. And to be fair, there's a lot of overlap depending on how you look at it. In most cases, people see Monitoring for ok/fail status, and Metrics for trending. I feel those are lacking, but I'll be honest in that I can't well articular why.</p>

<p>As an alternative that I can articulate, I see monitoring as being composed of 4 disciplines (areas of study):</p>

<ol>
<li>Meters: The collecting of data points (both numeric and ok/fail).</li>
<li>Thresholds: The automatic analysis of data points to signify some event.</li>
<li>Responses: The manual and automatic actions that come after Thresholds trip.</li>
<li>Presentations: The dashboards, interfaces, and reports that people view, manipulate, and receive.</li>
</ol>


<p>I picked these pieces because they each have ramifications to various consumers (and producers) of the monitoring system. This do not represent the underlying technologies,but can be used to identify requirements. They also don't represent all of the . I see them as features that users consider important from a monitoring system.</p>

<p>Using these, look at some of the use cases:</p>

<ul>
<li><p>A developer cares about Meters from the standpoints of identifying application Meters that matter, and the API for how to expose or pass those Meters off (something critical to remember is that a poor API will never be used). In many cases, the developer doesn't care about Thresholds or Responses (arguably, if the developer does operational role, yes, but I'm considering that the op role). The developer wants to see a Presentation where they can get information out for their run of their specific pieces, for a load test, etc.</p></li>
<li><p>A planner cares about Meters from the perspective of specifying some application Meters that matter. He doesn't care too much about Thresholds or Responses. He wants to see a Presentation of the long term trends of the running apps.</p></li>
<li><p>An operator cares about Meters from the perspective of having to make sure the plumbing is there to support it (e.g. snmp infrastructure, collectd infrastructure, storage, etc). He needs Thresholds to have valid meaning so that there aren't many false positives. He is typically going to be doing or watching the Responses. He needs to have a Presentation that shows the current ok/fail status of everything, and if he's astute, he'll be watching for unrecognized local trends.</p></li>
</ul>


<p>These are high level use cases, and may not reflect directly the role differences that are cropping up. We can take these and be more specific about them, but for this blog, I'm going to be fairly generic.</p>

<p>These disciplines also show some of the differences that have cropped up between devs and ops. Generally (and yes, there are plenty of counter examples), devs care about the Meters and Presentations, while ops care about Thresholds and Responses. This is reflected by the typical tool choices.</p>

<ul>
<li><p>Graphite is a dev tool. Why? Because it focuses on the Presentation.</p></li>
<li><p>Collectd is a dev tool. Why? Because it focuses on the Meter API.</p></li>
<li><p>Nagios ia an ops tool. Why? Because it focuses on the Thresholds.</p></li>
<li><p>I got nothing on Responses as there's some tools out there (knowledge bases, Orchestrator, etc) but nothing that I feel is too common.</p></li>
</ul>


<p>Just in here, I have two discussion points that show a bit of knowledge about those who compose the monitoring community. I hope this language will help additional discussions. A lot can be said for each of the disciplines. They probably deserve different posts on their own, but I'm not ready for that yet. Instead, I'll close with a potpurri of miscellaneous comments:</p>

<ul>
<li><p>It's naive to think that each discpline is self contained. They definitely have impact on each other from a practical standpoint.</p></li>
<li><p>Meters have at least two different subdisciplines: indirect Meters and live checks. This should not be confused with collectd pushes versus snmp polls or the like. I put both of those in the first category. The key difference is "Is this an observation of other data (# of bytes on an ethernet interface, # of errors in an error log, average user request transaction latency, etc), or is this an action that I'm performing to get some kind of status (synthetic transaction)?"</p></li>
<li><p>I'm still trying to sort out how single error events (say an error message from a user's transaction, and snmp trap, etc) play with counting the number of errors. The later easily fits in Meter, but I'm not sure how to address the former. In the snmp trap situation, there's typically a "countable" number of traps and sources that those can come from, so one could theoretically create a Meter for each of those. In the user error case, it's getting past "countable." Do you have a separate Meter for <em>every</em> user and does that have to be defined? There is probably some overlap with indirect Meters and live checks, but I'm still thinking about that. (And YES I know I'm useing "countable" incorrectly - I'm trying to signify the scale and it's impact on managability)</p></li>
<li><p>Along the lines of snmp traps (and single error events in general), these can fall into the auto clearing Thresholds, or the manually clearing Thresholds.</p></li>
<li><p>Thresholds can have a combination of static and dynamic (derived from pervious data), current values (e.g. is this drive full?) and projected values (e.g. will this disk fill up in the next 4 hours?), and probably several other dimensions.</p></li>
<li><p>I'm very apposed to a system where you can only determine Thresholds at the point of the Meters. Sometimes the Meter has sufficient information to make that decision (e.g. static Threshold), other times it does not (e.g. Meter dependencies, dynamic Meters, etc).</p></li>
<li><p>Meters and at least Thresholds can also have their own Meters: how often was this Threshold in the tripped state? I.e. SLA counting.</p></li>
<li><p>Meters need to have some variabilty of time in time. If I'm looking at live debugging, I probably want much finer granularity (5 second/1 second?) than if I'm looking at capacity planning. While disk is cheap, can we really record all Meters at 5 second or 1 second intervals all the time? Does that have application impacts? Does it make more sense to say "for the next 15 minutes, record 5 second intervals <em>for these specific Meters that I'm observing</em>? (Presentation systems also have to account for this.)</p></li>
<li><p>Responses can be manual (e.g. I see a disk filling up, so I'm going to go clean up temp files) or automatic (e.g. a process sees a disk filling up, so it goes and cleans up time files). Heh - "If you can't make it a process, you can't automate it." The Responses really reflect a maturity of the overall application response cycle. In that cycle, it typically goes: operator sees the alert and responds manually, operator writes up the typical response so other operators can response accordingly, someone comes along and automates the response so the write up can be much shorter. The side effect of this lifecycle is that Response systems include the knowledge bases that the complex/unautomated responses are collected in.</p></li>
</ul>

]]></content>
  </entry>
  
</feed>
